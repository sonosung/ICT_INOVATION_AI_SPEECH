{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO6KM6cjBCxacU7Iv8UD4JH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##README\n","##2024.09.30(월) 시작.\n","\n","### 프로젝트 목표:\n","- 음성을 텍스트로 변환하고, 텍스트를 번역한 후 음성으로 출력하는 시스템 개발."],"metadata":{"id":"1usVBhOfEWj9"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9dOA6KfDgvc","executionInfo":{"status":"ok","timestamp":1727704353034,"user_tz":-540,"elapsed":43036,"user":{"displayName":"Moon Music","userId":"02360968629997973549"}},"outputId":"3572c1ed-5d20-4857-c34f-7de45bfe7a89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl.metadata (28 kB)\n","Collecting gTTS\n","  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n","Collecting googletrans==4.0.0rc1\n","  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting openai-whisper\n","  Downloading openai-whisper-20240927.tar.gz (800 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.0/800.0 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting httpx==0.13.3 (from googletrans==4.0.0rc1)\n","  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (2024.8.30)\n","Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading hstspreload-2024.9.1-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0rc1) (1.3.1)\n","Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n","Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n","Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n","Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n","Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n","Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n","Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0rc1)\n","  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n","Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n","Collecting tiktoken (from openai-whisper)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting triton>=2.0.0 (from openai-whisper)\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n","Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n","Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n","Downloading hstspreload-2024.9.1-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n","Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: googletrans, openai-whisper\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=0a538d5978f4408ac0d9f24593b240b90ff9e87ff66bb57fd6b3e47876b3b465\n","  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20240927-py3-none-any.whl size=802818 sha256=f76af2d1dbf1eca80ac8c35b47caabee27df795eaa23b9289918f5f4f7d832cd\n","  Stored in directory: /root/.cache/pip/wheels/1c/d0/fd/81c5b31ba2016ac95f2f8e41d0e7016f2aab2a0bd306a7ab59\n","Successfully built googletrans openai-whisper\n","Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, triton, idna, hstspreload, h2, httpcore, tiktoken, SpeechRecognition, httpx, gTTS, openai-whisper, googletrans\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","Successfully installed SpeechRecognition-3.10.4 chardet-3.0.4 gTTS-2.5.3 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.9.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 openai-whisper-20240927 rfc3986-1.5.0 tiktoken-0.7.0 triton-3.0.0\n","usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n","               [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}]\n","               [--verbose VERBOSE] [--task {transcribe,translate}]\n","               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n","               [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE]\n","               [--patience PATIENCE] [--length_penalty LENGTH_PENALTY]\n","               [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT]\n","               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16]\n","               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n","               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n","               [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD]\n","               [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS]\n","               [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS]\n","               [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT]\n","               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n","               [--clip_timestamps CLIP_TIMESTAMPS]\n","               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n","               audio [audio ...]\n","whisper: error: the following arguments are required: audio\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,156 kB]\n","Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n","Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.5 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,586 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,318 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,595 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,445 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n","Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,355 kB]\n","Fetched 19.0 MB in 5s (4,003 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","54 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n"]}],"source":["!pip install SpeechRecognition gTTS googletrans==4.0.0rc1 openai-whisper\n","\n","!whisper\n","\n","!sudo apt update && sudo apt install ffmpeg"]},{"cell_type":"code","source":["#라이브러리 설치\n","import speech_recognition as sr\n","from gtts import gTTS\n","from googletrans import Translator\n","import whisper\n","from googletrans import Translator\n","\n","# Whisper 모델 로드\n","model = whisper.load_model(\"large\")  # 'tiny', 'base', 'small', 'medium', 'large' 중 선택"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zblWlnTvuzXP","executionInfo":{"status":"ok","timestamp":1727704483987,"user_tz":-540,"elapsed":70425,"user":{"displayName":"Moon Music","userId":"02360968629997973549"}},"outputId":"fcc66c77-64fc-429d-c4bd-95ff29b2a6ce"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████████████████████████████████| 2.88G/2.88G [00:33<00:00, 93.6MiB/s]\n","/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(fp, map_location=device)\n"]}]},{"cell_type":"code","source":["# 음성 인식 함수\n","def recognize_speech_from_file(file_path):\n","    # 음성 파일을 인식\n","    result = model.transcribe(file_path, language='en')\n","    text = result['text']\n","    print(\"인식된 텍스트:\", text)\n","    return text\n","\n","# 텍스트 번역 함수\n","def translate_text(text, target_language='ko'):\n","    translator = Translator()\n","    try:\n","        translated = translator.translate(text, dest=target_language)\n","        print(text, translated.text)\n","        return translated.text\n","    except Exception as e:\n","        print(\"번역 중 오류가 발생했습니다:\", e)\n","        return None\n","\n","# 음성 출력 함수\n","def speak(text):\n","\ttts = gTTS(text=text, lang='ko')\n","\ttts.save('voice.mp3')\n","\n","# 음성 파일 경로\n","audio_file_path = \"audio/20240806004644.m4a\"  # 인식할 음성 파일 경로\n","recognized_text = recognize_speech_from_file(audio_file_path)\n","\n","# 번역 실행\n","if recognized_text:\n","    translated_text = translate_text(recognized_text, target_language='ko')  # 영어로 번역\n","\n","#음성 출력 실행\n","speak(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xraNhn-UIDVM","executionInfo":{"status":"ok","timestamp":1727705199345,"user_tz":-540,"elapsed":6408,"user":{"displayName":"Moon Music","userId":"02360968629997973549"}},"outputId":"edc3f374-55a4-4aa1-fe4f-0a458b7dceb5"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["인식된 텍스트:  I still remember, like suddenly I remember those, that song on TikTok. The guy was teaching people Korean was, Chicken mokgo shippoyo. Something like that. So, with jajangmyeon, jajangmyeon. I'm not, how to pronounce oh, but yeah. Yeah, I think something like that.\n"," I still remember, like suddenly I remember those, that song on TikTok. The guy was teaching people Korean was, Chicken mokgo shippoyo. Something like that. So, with jajangmyeon, jajangmyeon. I'm not, how to pronounce oh, but yeah. Yeah, I think something like that. 나는 아직도 Tiktok의 그 노래를 갑자기 기억합니다.그 남자는 사람들에게 한국인, 치킨 모코 크고 Shippoyo를 가르치고 있었다.그런 것.Jajangmyeon, Jajangmyeon과 함께.난 아니에요예, 그런 것 같아요.\n"]}]},{"cell_type":"markdown","source":["2024.09.30 위에 까지 성공. 음성 파일에서 텍스트를 추출하고, 특정 언어로 번역한 후, 음성 파일로 출력을 했다. 야호!"],"metadata":{"id":"YpQ-5WVqQjJ5"}},{"cell_type":"code","source":["import IPython\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import requests\n","import torch\n","import torchaudio\n","\n","matplotlib.rcParams[\"figure.figsize\"] = [16.0, 4.8]\n","\n","torch.random.manual_seed(0)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(torch.__version__)\n","print(torchaudio.__version__)\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZ9ZHWYQKmbt","executionInfo":{"status":"ok","timestamp":1727703743345,"user_tz":-540,"elapsed":839,"user":{"displayName":"Moon Music","userId":"02360968629997973549"}},"outputId":"930b3211-9861-47b6-8b05-d753f5bd7a5b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2.4.1+cu121\n","2.4.1+cu121\n","cuda\n"]}]},{"cell_type":"code","source":["IPython.display.Audio(translated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"id":"7tBG15JTKPkg","executionInfo":{"status":"error","timestamp":1727703746366,"user_tz":-540,"elapsed":9,"user":{"displayName":"Moon Music","userId":"02360968629997973549"}},"outputId":"0d7d3f25-4d73-4c6a-d490-21d9a9ef72ce"},"execution_count":6,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"rate must be specified when data is a numpy array or list of audio samples.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-20edd4c89333>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rate must be specified when data is a numpy array or list of audio samples.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."]}]}]}